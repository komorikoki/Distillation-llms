{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments, AutoTokenizer\n",
    "device='cuda'\n",
    "# モデルの準備\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Mesozoic era is represented in the park by the model rock exposure showing a succession of beds namely the Jurassic and Cretaceous by models of dinosaurs and other animals known from mesozoic fossils and by suitable vegetation both living plants and models '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset=ds[\"train\"].shuffle(seed=42).select(range(20000))\n",
    "validation_dataset=ds[\"validation\"].shuffle(seed=42).select(range(3500))\n",
    "train_dataset = train_dataset[\"text\"]\n",
    "train_dataset = [item for item in train_dataset if item != '' and len(item) >= 50 and '@' not in item]\n",
    "validation_dataset=validation_dataset[\"text\"]\n",
    "validation_dataset = [item for item in validation_dataset if item != '' and len(item) >= 50 and '@' not in item]\n",
    "\n",
    "import re\n",
    "\n",
    "train_dataset = [re.sub(r'[^a-zA-Z ]', '', item) for item in train_dataset]\n",
    "train_dataset = [re.sub(r'\\s+', ' ', item) for item in train_dataset]\n",
    "validation_dataset = [re.sub(r'[^a-zA-Z ]', '', item) for item in validation_dataset]\n",
    "validation_dataset = [re.sub(r'\\s+', ' ', item) for item in validation_dataset]\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset: 100%|██████████| 4063/4063 [00:02<00:00, 2020.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# 入力とラベルを設定\n",
    "train_data = []\n",
    "for text in tqdm(train_dataset, desc=\"Tokenizing dataset\"):\n",
    "    tokenized = tokenizer(text, padding=\"max_length\", max_length=32, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = tokenized['input_ids'].squeeze().tolist()\n",
    "    attention_mask = tokenized['attention_mask'].squeeze().tolist()\n",
    "    # 次の単語のインデックスをラベルとして追加\n",
    "    labels = input_ids[1:] + [tokenizer.pad_token_id]  # 最初の単語を除いて次の単語をラベルにする\n",
    "    labels[-1]=-100\n",
    "    train_data.append({\"input_ids\": input_ids, \"labels\": labels, \"attention_mask\":attention_mask})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = [item[\"input_ids\"] for item in train_data]\n",
    "labels = [item[\"labels\"] for item in train_data]\n",
    "attention_mask = [item[\"attention_mask\"] for item in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train=[]\n",
    "for i in range(250):\n",
    "    batch_input=[input_ids[i+0], input_ids[i+1], input_ids[i+2], input_ids[i+3]]\n",
    "    batch_train.append(batch_input)\n",
    "input_ids=batch_train\n",
    "\n",
    "batch_train=[]\n",
    "for i in range(250):\n",
    "    batch_input=[labels[i+0], labels[i+1], labels[i+2], labels[i+3]]\n",
    "    batch_train.append(batch_input)\n",
    "labels=batch_train\n",
    "\n",
    "batch_train=[]\n",
    "for i in range(250):\n",
    "    batch_input=[attention_mask[i+0], attention_mask[i+1], attention_mask[i+2], attention_mask[i+3]]\n",
    "    batch_train.append(batch_input)\n",
    "attention_mask=batch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_tensor = torch.tensor(batch_train, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "attention_mask_tensor = torch.tensor(attention_mask, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# オプティマイザの定義\n",
    "optimizer = AdamW(teacher_model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_tensor=input_ids_tensor.to(device)\n",
    "labels_tensor=labels_tensor.to(device)\n",
    "attention_mask_tensor = attention_mask_tensor.to(device)\n",
    "teacher_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000, 578, 36684, 96614, 292, 11639, 374, 15609, 304, 279, 6246, 555, 279, 1646, 7091, 14675, 9204, 264, 50787, 315, 28036, 32125, 279, 84474, 323, 356, 2171, 77140, 555, 4211, 315, 65375], [128000, 5929, 14588, 374, 264, 49770, 7701, 65765, 1370, 481, 922, 7102, 4398, 430, 4860, 3508, 27052, 374, 264, 2917, 481, 10723, 17563, 477, 9687, 7865, 477, 422, 433, 374, 459, 13365], [128000, 59895, 2214, 10554, 4562, 29607, 56872, 6267, 279, 8857, 315, 279, 5597, 304, 279, 71085, 1162, 56872, 29786, 304, 459, 7274, 449, 578, 1561, 4356, 8691, 1102, 574, 8196, 430, 420], [128000, 16450, 10357, 321, 5676, 3468, 46965, 386, 8512, 8384, 648, 274, 6691, 374, 264, 15779, 889, 374, 439, 459, 9191, 289, 12329, 810, 6940, 349, 2373, 315, 8384, 648, 3005, 574]]\n",
      "[[578, 36684, 96614, 292, 11639, 374, 15609, 304, 279, 6246, 555, 279, 1646, 7091, 14675, 9204, 264, 50787, 315, 28036, 32125, 279, 84474, 323, 356, 2171, 77140, 555, 4211, 315, 65375, -100], [5929, 14588, 374, 264, 49770, 7701, 65765, 1370, 481, 922, 7102, 4398, 430, 4860, 3508, 27052, 374, 264, 2917, 481, 10723, 17563, 477, 9687, 7865, 477, 422, 433, 374, 459, 13365, -100], [59895, 2214, 10554, 4562, 29607, 56872, 6267, 279, 8857, 315, 279, 5597, 304, 279, 71085, 1162, 56872, 29786, 304, 459, 7274, 449, 578, 1561, 4356, 8691, 1102, 574, 8196, 430, 420, -100], [16450, 10357, 321, 5676, 3468, 46965, 386, 8512, 8384, 648, 274, 6691, 374, 264, 15779, 889, 374, 439, 459, 9191, 289, 12329, 810, 6940, 349, 2373, 315, 8384, 648, 3005, 574, -100]]\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[0])\n",
    "print(labels[0])\n",
    "print(attention_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:06<00:00, 36.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(250)):\n",
    " \n",
    "    input_ids=input_ids_tensor[i]\n",
    "    labels=labels_tensor[i]\n",
    "    attention_mask=attention_mask_tensor[i]\n",
    "    optimizer.zero_grad()\n",
    "    outputs = teacher_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
