{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./cqatrains1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "model.eval()\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,   2688,    265,  41798,    374,   3967,    369,   1202,  15022,\n",
       "          48911,     11,    449,    279,  19957,    538,    665,  16608,    304,\n",
       "           4498,    220,    679,     20,  55689,    220,     18,     11,  23411,\n",
       "            505,    264,   7463,    315,    220,    972,     11,  10132,    320,\n",
       "            777,     13,     22,  53172,    578,  14584,   5643,    315,    279,\n",
       "          37191,    538,   9731,    311,   4478,   4315,    279,   1948,    220,\n",
       "            605,    311,    220,    868,    304,    279,   7140,    369,   5426,\n",
       "           3495,  23978,     13,    578,  12374,  12659,    264,   2536,   5621,\n",
       "           6765,    535,   4216,   1957,   4947,    430,   6276,  16584,   4236,\n",
       "            311,   2980,  26360,    311,  44564,  41798,    439,   1664,    439,\n",
       "            904,   1023,  31252,    311,    902,    814,   1051,  11928,     13,\n",
       "            220,     16,     11,   3443,    315,    279,    220,     18,     11,\n",
       "          23411,    320,   2137,     13,     16,  11587,   1051,  16584,   1234,\n",
       "            279,   4216,   1957,   3197,     13,   2467,   5600,   4236,   3782,\n",
       "            505,    220,     16,     11,  15134,   1579,   8853,    323,    279,\n",
       "           5578,   5575,  31796,    810,   1109,    220,  11711,   8931,    311,\n",
       "          44564,  41798,     11,   3339,    433,  36659,    279,   1455,  18740,\n",
       "          12374,    304,    279,   3723,   4273,     13,   6104,    682,  16661,\n",
       "           4236,   3240,    304,    279,   9304,    315,    279,   5629,   9941,\n",
       "            315,  19241,     11,    220,    914,      4,    617,  16717,    814,\n",
       "           3197,    311,   4007,    304,    279,  18250,  19071,    477,   3674,\n",
       "          36788,     11,    220,   1187,      4,    304,  15009,     11,    220,\n",
       "           1187,      4,    304,   2626,     11,    220,   1187,      4,    304,\n",
       "           8198,     11,    323,    220,     18,      4,    304,  18112,  76241,\n",
       "          11668,    315,   4236,   1051,  16584,    311,  44564,  41798,    304,\n",
       "           4498,    220,    679,     20,     30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=\"Notre Dame is known for its competitive admissions, with the incoming class enrolling in fall 2015 admitting 3,577 from a pool of 18,156 (19.7%). The academic profile of the enrolled class continues to rate among the top 10 to 15 in the nation for national research universities. The university practices a non-restrictive early action policy that allows admitted students to consider admission to Notre Dame as well as any other colleges to which they were accepted. 1,400 of the 3,577 (39.1%) were admitted under the early action plan. Admitted students came from 1,311 high schools and the average student traveled more than 750 miles to Notre Dame, making it arguably the most representative university in the United States. While all entering students begin in the College of the First Year of Studies, 25% have indicated they plan to study in the liberal arts or social sciences, 24% in engineering, 24% in business, 24% in science, and 3% in architecture.What percentage of students were admitted to Notre Dame in fall 2015?\"\n",
    "tokenized=tokenizer(data, padding='longest', max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=tokenized['input_ids'], attention_mask=tokenized['attention_mask'], labels=tokenized['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6324\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "probabilities = F.softmax(logits, dim=-1)\n",
    "probabilities = probabilities[0][-1]\n",
    "probabilities.shape\n",
    "\n",
    "topk_values, top3_indices = torch.topk(probabilities, k=3)\n",
    "\n",
    "prob_top=tokenizer.decode(top3_indices)\n",
    "print(prob_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
