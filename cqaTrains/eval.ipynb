{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./cqatrains6/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "model.eval()\n",
    "\n",
    "model.eval()\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,     34,     25,  12174,     11,   1071,  39431,  14643,     11,\n",
       "           1053,    539,    433,    387,   6555,    422,    584,   1436,      0,\n",
       "           8442,    279,   2523,  85880,   3245,    374,   1268,   1364,   2751,\n",
       "           1555,    279,   7147,     13,    358,    656,    539,   1518,   1268,\n",
       "           1694,  33173,   1053,   1520,   1077,    311,    656,    430,     13,\n",
       "           8170,    838,     11,    279,  74665,     11,  14760,    304,   2345,\n",
       "          12174,     11,    499,   2466,  18754,      0,   1364,   3287,   1431,\n",
       "            733,   1555,    433,     26,   1364,   1193,   3463,   1364,   1550,\n",
       "             13,   8489,     11,   1243,     11,   1071,  23720,  14295,     11,\n",
       "            358,   1390,    311,   1781,    433,   2288,     13,   8155,   3814,\n",
       "            994,    358,    574,    304,   4950,    358,   6818,    311,    733,\n",
       "            311,   6212,     11,    323,    311,    636,   1555,    279,   7147,\n",
       "             26,    719,    994,    358,  11299,  33173,    358,  29695,    682,\n",
       "            922,    433,     11,    323,  57636,    430,    358,    574,  14363,\n",
       "             11,    323,    430,    279,  10896,   6688,    757,    264,   2466,\n",
       "           9168,    315,   2555,   4917,   1907,     13,  16770,     11,    719,\n",
       "             11,   1071,   8170,    838,     11,   1054,   9210,    574,   1606,\n",
       "            499,   6818,     13,  30505,   3287,   1431,   1456,     11,    499,\n",
       "           1440,     13,   3005,   7020,   4400,    922,   1694,  33173,  12222,\n",
       "           1364,  39826,    709,   1196,    616,     11,    358,   3287,   1431,\n",
       "           1440,    358,    574,  33173,  12222,    358,  39826,    709,     11,\n",
       "           3060,   2476,  19089,  23720,  14295,     13,  39431,  14643,   7111,\n",
       "           1633,  24219,     11,   8051,    568,    574,    279,  25655,     11,\n",
       "            323,   1071,     11,   1054,  32576,    422,  30505,    574,   1618,\n",
       "             11,   1364,   1053,   3371,    603,   1268,    311,    656,    433,\n",
       "           2029,     13,     48,     25,   3639,   1587,  30505,    656,     30,\n",
       "             32,     25,   1148,   1364]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=\"\"\n",
    "tokenized=tokenizer(data, padding='longest', max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=tokenized['input_ids'], attention_mask=tokenized['attention_mask'], labels=tokenized['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29749,    34,    34,   763,   931,  1071, 39431, 14643,   660,   387,\n",
      "           539,   433,   387,  6555,    32,  1390,  1436,    32,  5995, 10973,\n",
      "            32, 14643,  3201,   502,  1790,   574,  2751,   387,   279,   315,\n",
      "           679,  1541,   358,   433,   433,   387,   279,   574,   539,  1520,\n",
      "          7102,  1520,   539,  7077,   539,   433,   596,  5131,  7147,   422,\n",
      "           596,   994,   220,   220,    11,  1071,   358,  1077,  3254,    32,\n",
      "          2751,  1555,  3320,  1555,   279,   374,    26,  3287,   706,   922,\n",
      "          3287,   539,  1077, 17872,   596,   279,   279, 39431,   358,   323,\n",
      "           679,   656,   539,   656,  1781,    26,   574,  8489,  8155,  3814,\n",
      "           279,   656,   264,   279,  4950,   358,   264,  6212,  3201,   387,\n",
      "          6212,    26,  6212,  6212,   369,   433,  7147,    13,  3005,  1077,\n",
      "           358,   574,   539,  6212,   358, 15447,  2574,   682,  2288,  2288,\n",
      "           279,  1561,   323,  1541,   264,    26,   323,   539,    13,  7147,\n",
      "           596,  1077,   757,  2539,  2466,  3254,   584,   574,  1077,    11,\n",
      "          5926,   268, 16770, 18073,    11, 39431,   838,    11,   279,  1771,\n",
      "           499,   406,    26,  2466,  6818,  8489,   574,  1431,   733,  1456,\n",
      "           719,  6818,    32, 30505,  3287,  1077,  1077,  1077,   268,  1053,\n",
      "           358,  3287,  1561,   709,    25,    11,  1077,  1541,  1431,  1028,\n",
      "            13,   358, 36999,   358,   358,   358,  1561,  1196,   358,    11,\n",
      "            82, 10785,   358,    11,   358, 14643,    11,   555,   433,   482,\n",
      "           719,    11,  3287,  2103,  7147, 11745,    11,  1023, 39431, 21319,\n",
      "          9210,    25,   584,  3287,   539,  3254,  3254,  3287,   387,  1077,\n",
      "          5694,  1790,   656,   539,     0,  1440,  1077,    25,  1364,  1364,\n",
      "          2555,  3287,   539,    32,    25,  1148,  1364,  3287]])\n",
      " TuCC In000 said Ranulfated be not it be niceA want couldA necessary absoluteAulf away new much was got be the of201 don I it it be the was not help race help not happened not it's currently wall if's when , said I her singleA got through Br through the is; didn has about didn not herinda's the the Ran I and201 do not do think; was Well Last night the do a the bed I a sleep away be sleep; sleep sleep for it wall. She her I was not sleep I clothes things all too too the New and don a; and not. wall's her me full big single we was her,192en Ah handled, Ranval, theains yount; big tried Well was’t go try but triedA Alice didn her her heren would I didn New up:, her don’t te. I virgin I I I New.W I,s Wil I, Iulf, by it - but, didn still wall breath, other Ran groundsthat: we didn not single single didn be her themselves much do not! know her: she she something didn notA: what she didn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "most_likely_token = torch.argmax(probabilities[:, :, :], dim=-1)\n",
    "print(most_likely_token)\n",
    "most_likely_token = tokenizer.decode(most_likely_token[0])\n",
    "print(most_likely_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
